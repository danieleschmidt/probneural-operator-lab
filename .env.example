# Environment Configuration for ProbNeural Operator Lab
# Copy this file to .env and modify values as needed

# =============================================================================
# Core Configuration
# =============================================================================

# Debug mode (development only)
DEBUG=false

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Random seed for reproducible experiments
RANDOM_SEED=42

# =============================================================================
# Compute Configuration
# =============================================================================

# CUDA device selection
CUDA_VISIBLE_DEVICES=0

# Enable CUDA if available
USE_CUDA=true

# Memory allocation strategy
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# =============================================================================
# Data and Model Paths
# =============================================================================

# Root directory for datasets
DATA_ROOT=./data

# Directory for model checkpoints
CHECKPOINT_DIR=./checkpoints

# Directory for experiment outputs
OUTPUT_DIR=./outputs

# Directory for cached data
CACHE_DIR=./cache

# =============================================================================
# Training Configuration
# =============================================================================

# Default batch size
BATCH_SIZE=32

# Number of data loading workers
NUM_WORKERS=4

# Mixed precision training
USE_AMP=true

# Gradient clipping value
GRAD_CLIP_VALUE=1.0

# =============================================================================
# Uncertainty Quantification
# =============================================================================

# Default prior precision for Laplace approximation
PRIOR_PRECISION=1.0

# Number of posterior samples for prediction
NUM_POSTERIOR_SAMPLES=100

# Temperature scaling initial value
TEMPERATURE_SCALE=1.0

# =============================================================================
# Active Learning Configuration
# =============================================================================

# Default acquisition function
ACQUISITION_FUNCTION=bald

# Active learning budget
AL_BUDGET=1000

# Batch size for active learning queries
AL_BATCH_SIZE=10

# =============================================================================
# Database Configuration (for experiment tracking)
# =============================================================================

# Database URL (SQLite for local development)
DATABASE_URL=sqlite:///experiments.db

# Redis URL for caching and job queues
REDIS_URL=redis://localhost:6379/0

# =============================================================================
# API and Serving Configuration
# =============================================================================

# API server host
API_HOST=0.0.0.0

# API server port
API_PORT=8000

# Maximum request size (in MB)
MAX_REQUEST_SIZE=100

# Request timeout (in seconds)
REQUEST_TIMEOUT=300

# =============================================================================
# Monitoring and Logging
# =============================================================================

# Weights & Biases API key (for experiment tracking)
# WANDB_API_KEY=your_wandb_api_key_here

# Weights & Biases project name
WANDB_PROJECT=probneural-operator-lab

# TensorBoard log directory
TENSORBOARD_LOG_DIR=./logs/tensorboard

# MLflow tracking URI
# MLFLOW_TRACKING_URI=http://localhost:5000

# =============================================================================
# Testing Configuration
# =============================================================================

# Skip slow tests
SKIP_SLOW_TESTS=false

# Skip GPU tests if no GPU available
SKIP_GPU_TESTS=false

# Test data directory
TEST_DATA_DIR=./tests/data

# =============================================================================
# Cloud Storage Configuration
# =============================================================================

# AWS S3 bucket for data storage
# AWS_S3_BUCKET=your-s3-bucket

# AWS region
# AWS_REGION=us-east-1

# Google Cloud Storage bucket
# GCS_BUCKET=your-gcs-bucket

# Azure storage account
# AZURE_STORAGE_ACCOUNT=your-storage-account